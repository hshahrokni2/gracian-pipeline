#!/usr/bin/env python3
"""
Test script for Option 3 refactored pipeline.

Validates that:
1. BaseExtractor methods work correctly
2. IntegratedBRFPipeline inherits and uses them properly
3. Extraction coverage improves from 9.1% to >50%
"""

import sys
import json
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from integrated_brf_pipeline import IntegratedBRFPipeline


def print_section(title: str):
    """Print section header"""
    print(f"\n{'='*80}")
    print(f"  {title}")
    print(f"{'='*80}")


def test_refactored_pipeline():
    """Test the refactored pipeline with real LLM extraction"""

    print_section("Option 3 Refactored Pipeline Test")

    # Test PDF
    test_pdf = Path("test_pdfs/brf_198532.pdf")
    if not test_pdf.exists():
        print(f"‚ùå Test PDF not found: {test_pdf}")
        return

    print(f"\nüìÑ Test Document: {test_pdf.name}")

    # Initialize refactored pipeline
    print("\nüîß Initializing refactored pipeline...")
    pipeline = IntegratedBRFPipeline(
        mode='fast',
        enable_caching=True
    )

    # Extract
    print("\nüöÄ Running extraction...")
    start_time = time.time()

    try:
        result = pipeline.extract_document(str(test_pdf))
        elapsed = time.time() - start_time

        print_section("EXTRACTION RESULTS")

        # Print summary
        print(f"\nüìä Extraction Summary:")
        print(f"   ‚Ä¢ Total time: {elapsed:.1f}s")
        print(f"   ‚Ä¢ Mode: {result.mode}")
        print(f"   ‚Ä¢ PDF topology: {result.topology.classification}")
        print(f"   ‚Ä¢ Agents run: {len(result.agent_results)}")

        # Print agent results
        print(f"\nü§ñ Agent Results:")
        for agent_id, agent_data in result.agent_results.items():
            field_count = len([v for v in agent_data.values() if v])
            print(f"   ‚Ä¢ {agent_id}: {field_count} fields extracted")

            # Show sample data (first 3 fields)
            if agent_data:
                print(f"      Sample data:")
                for i, (k, v) in enumerate(list(agent_data.items())[:3]):
                    if k != 'evidence_pages':
                        print(f"         - {k}: {str(v)[:80]}")
                    if i >= 2:
                        break

        # Print quality metrics
        print(f"\nüìà Quality Metrics:")
        quality = result.quality_metrics
        print(f"   ‚Ä¢ Coverage: {quality.get('coverage', 0)*100:.1f}%")
        print(f"   ‚Ä¢ Numeric QC Pass: {quality.get('numeric_qc_pass', False)}")
        print(f"   ‚Ä¢ Evidence Ratio: {quality.get('evidence_ratio', 0)*100:.1f}%")
        print(f"   ‚Ä¢ Overall Score: {quality.get('overall_score', 0)*100:.1f}%")
        print(f"   ‚Ä¢ Needs Coaching: {quality.get('needs_coaching', False)}")

        # Print integration metrics
        print(f"\nüîß Integration Metrics:")
        int_metrics = result.integration_metrics
        print(f"   ‚Ä¢ Structure Detection: {'‚úÖ' if int_metrics.structure_detection_success else '‚ùå'}")
        print(f"   ‚Ä¢ Data Linking: {'‚úÖ' if int_metrics.data_linking_success else '‚ùå'}")
        print(f"   ‚Ä¢ Validation: {'‚úÖ' if int_metrics.validation_success else '‚ùå'}")

        # Save result
        output_file = Path("results/refactored_pipeline_test_result.json")
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "pdf": str(test_pdf),
                "elapsed_time": elapsed,
                "mode": result.mode,
                "topology": result.topology.__dict__,
                "agent_results": result.agent_results,
                "quality_metrics": result.quality_metrics,
                "integration_metrics": {
                    "structure_detection_success": int_metrics.structure_detection_success,
                    "data_linking_success": int_metrics.data_linking_success,
                    "validation_success": int_metrics.validation_success,
                    "pass_rate": int_metrics.pass_rate,
                    "errors": int_metrics.errors,
                    "warnings": int_metrics.warnings
                }
            }, f, indent=2, ensure_ascii=False)

        print(f"\nüíæ Result saved: {output_file}")

        # Success criteria
        print_section("SUCCESS CRITERIA CHECK")

        coverage = quality.get('coverage', 0)
        print(f"\n‚úÖ Extraction stub replaced: {coverage > 0.1}")
        print(f"   ‚Ä¢ Coverage: {coverage*100:.1f}% (was 9.1%)")

        if coverage > 0.5:
            print(f"\nüéâ SUCCESS! Coverage improved from 9.1% to {coverage*100:.1f}%")
            print(f"   Target: >50%, Achieved: {coverage*100:.1f}%")
            return True
        elif coverage > 0.1:
            print(f"\n‚ö†Ô∏è  PARTIAL SUCCESS! Coverage: {coverage*100:.1f}% (target: >50%)")
            print(f"   Extraction is working but may need tuning")
            return True
        else:
            print(f"\n‚ùå FAILURE! Coverage still: {coverage*100:.1f}%")
            return False

    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_refactored_pipeline()
    sys.exit(0 if success else 1)
