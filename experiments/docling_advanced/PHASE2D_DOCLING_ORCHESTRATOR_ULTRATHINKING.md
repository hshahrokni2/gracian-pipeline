# Phase 2D: Docling-Based Orchestrator - ULTRATHINKING Analysis

**Date**: 2025-10-08
**Status**: ðŸ§  ULTRATHINKING IN PROGRESS

---

## ðŸŽ¯ The Paradigm Shift

### What We Were Doing Wrong:
```python
# âŒ WRONG: Search PDF text for sections, then search again for keywords
1. Docling extracts structure â†’ Get section headings
2. Search PDF raw text for headings â†’ Get pages (FAILS on scanned PDFs)
3. Search PDF raw text for keywords â†’ Get pages (FAILS on scanned PDFs)
4. Pass pages to LLM
```

### What We Should Do (User's Insight):
```python
# âœ… RIGHT: Use Docling's structure metadata directly
1. Docling extracts structure â†’ Get sections WITH PAGE NUMBERS
2. Map section headings â†’ agents (semantic routing)
3. Use Docling's page metadata â†’ Pass correct pages to LLM
```

---

## ðŸ”¬ Root Cause Analysis (Confirmed)

### Evidence Ratio Problem:
- **Current**: 12.5% (1/8 agents provide evidence_pages)
- **Target**: â‰¥75% (6-7/8 agents)
- **Root Cause**: Agents receive wrong pages â†’ Can't find data â†’ Return empty

### Why Page Detection Failed:
1. **PyMuPDF Search Fails on Scanned PDFs**:
   - `fitz.open(pdf).page.get_text()` â†’ Returns `""`  for scanned pages
   - Keyword search in empty string â†’ Finds nothing
   - Falls back to heading-based pages [1,2,4,5]

2. **Financial Data on Different Pages**:
   - Heading "ResultatrÃ¤kning" might be on page 4
   - Actual financial TABLE might be on pages 7-8
   - LLM gets pages [1,2,4,5], doesn't see pages 7-8
   - Returns `evidence_pages: []`

---

## ðŸ’¡ ULTRATHINKING Solution: Docling Orchestrator

### Key Insight from Docling:
Docling **already** provides page information via:
1. **Provenance metadata**: `item.prov[0].page_no`
2. **Section ranges**: Start/end page for each section
3. **OCR text**: Full text from all pages (not just headings)

### Architecture Redesign:

```python
class DoclingOrchestrator:
    """
    Intelligent orchestrator that uses Docling structure metadata
    instead of searching raw PDF text.
    """

    def route_sections_to_agents(self, doc: DoclingDocument) -> Dict[str, List[int]]:
        """
        Map sections â†’ agents â†’ pages using Docling provenance.

        BEFORE (Text Search):
        - Search PDF text for "ResultatrÃ¤kning" â†’ page 4
        - Pass page 4 to financial_agent

        AFTER (Provenance-Based):
        - Get section "ResultatrÃ¤kning" from Docling
        - Extract prov[0].page_no â†’ page 4
        - Get section content span â†’ pages 4-7
        - Pass pages 4-7 to financial_agent
        """
        agent_page_map = {}

        for item, level in doc.iterate_items():
            if isinstance(item, SectionHeaderItem):
                # Get page from provenance (not text search!)
                page_no = item.prov[0].page_no if item.prov else None

                # Map heading to agent
                agent_id = self.semantic_router.classify(item.text)

                # Collect pages for agent
                if agent_id not in agent_page_map:
                    agent_page_map[agent_id] = []
                if page_no is not None:
                    agent_page_map[agent_id].append(page_no)

        return agent_page_map
```

---

## ðŸ”§ Implementation Strategy

### Phase 1: Extract Provenance Data (15 minutes)
**Goal**: Verify Docling provides `prov[0].page_no` for sections

**Current Diagnostic Running**:
```bash
python3 code/debug_docling_pages.py
# Will show: item.prov[0].page_no for each section
```

**Expected Output**:
```
Section #1: FÃ¶rvaltningsberÃ¤ttelse
  âœ… prov[0].page_no: 1

Section #2: ResultatrÃ¤kning
  âœ… prov[0].page_no: 7

Section #3: BalansrÃ¤kning
  âœ… prov[0].page_no: 8
```

### Phase 2: Update detect_structure() (10 minutes)
**Goal**: Preserve provenance page numbers in structure cache

```python
def detect_structure(self, pdf_path: str, topology: PDFTopology) -> StructureDetectionResult:
    # ... existing code ...

    for item, level in doc.iterate_items():
        if isinstance(item, SectionHeaderItem):
            # ENHANCEMENT: Extract page from provenance
            page_no = None
            if item.prov and len(item.prov) > 0:
                page_no = getattr(item.prov[0], 'page_no', None)

            section_info = {
                "heading": item.text,
                "level": level,
                "page": page_no,  # âœ… Now from provenance, not attribute
                "text_preview": item.text[:200] if hasattr(item, 'text') else ""
            }
            sections.append(section_info)
```

### Phase 3: Update _get_pages_for_sections() (15 minutes)
**Goal**: Use provenance data FIRST, text search as fallback

```python
def _get_pages_for_sections(
    self,
    pdf_path: str,
    section_headings: List[str],
    fallback_pages: int = 5,
    agent_id: str = None
) -> List[int]:
    """
    ENHANCED: Use Docling provenance first, then fallbacks.

    Priority:
    1. Docling provenance page numbers (âœ… Works on scanned PDFs)
    2. Expand to nearby pages (context around heading)
    3. Text search fallback (machine-readable PDFs only)
    4. First N pages (last resort)
    """
    pages = []

    # Method 1: Use Docling provenance (PRIORITY)
    if hasattr(self, 'structure_cache') and self.structure_cache:
        for heading in section_headings:
            for section in self.structure_cache.sections:
                if section['heading'] == heading and section.get('page') is not None:
                    page = section['page']
                    pages.append(page)

                    # âœ… ENHANCEMENT: Add nearby pages for context
                    # Financial sections often span 2-3 pages
                    if agent_id == 'financial_agent':
                        pages.extend([page+1, page+2])

                    break

    # Method 2: Text search fallback (for machine-readable PDFs)
    if not pages and self.topology.classification == "machine_readable":
        # ... existing text search code ...

    # Method 3: Last resort
    if not pages:
        pages = list(range(min(fallback_pages, self._get_pdf_page_count(pdf_path))))

    return sorted(set(pages))
```

---

## ðŸ“Š Expected Improvements

| Metric | Before (Phase 2C) | After (Phase 2D) | Reasoning |
|--------|-------------------|------------------|-----------|
| **Evidence Ratio** | 12.5% | â‰¥75% | Agents get correct pages with data |
| **Page Detection** | Text search (fails on scanned) | Provenance (works on scanned) | Docling OCR provides page metadata |
| **Financial Agent** | Pages [1,2,4,5], no data | Pages [7,8,9], has tables | Correct page numbers from structure |
| **Overall Score** | 56.2% | â‰¥87.5% | (100% coverage + 75% evidence) / 2 |

---

## âœ… Success Criteria

**Phase 2D Complete When**:
1. âœ… Provenance extraction verified (diagnostic shows `prov[0].page_no`)
2. âœ… `detect_structure()` captures page numbers from provenance
3. âœ… `_get_pages_for_sections()` uses provenance-based routing
4. âœ… Evidence ratio â‰¥75% on test document
5. âœ… financial_agent returns populated evidence_pages

---

**Next Action**: Wait for diagnostic (~2 min), then implement provenance-based routing.
