"""
Test suite for CalculatedFinancialMetrics with tolerant validation.

Week 2 Day 1-2 Implementation (2025-10-07)

Tests:
1. Debt per sqm calculation and validation (valid, warning, error tiers)
2. Solidarity percentage calculation and validation
3. Fee per sqm calculation and validation
4. Dynamic tolerance thresholds (small, medium, large amounts)
5. No data nulling (all tiers preserve extracted values)
6. Overall confidence aggregation
"""

import sys
from pathlib import Path

# Add gracian_pipeline to path
sys.path.insert(0, str(Path(__file__).parent))

from datetime import datetime
from gracian_pipeline.models.brf_schema import (
    CalculatedFinancialMetrics,
    get_financial_tolerance,
    FinancialData
)
from gracian_pipeline.models.base_fields import NumberField
import traceback


def test_dynamic_tolerance():
    """Test 1: Dynamic tolerance thresholds based on amount size."""
    print("\n" + "=" * 70)
    print("TEST 1: Dynamic Tolerance Thresholds")
    print("=" * 70)

    test_cases = [
        (50_000, "Small amount (<100k)"),
        (500_000, "Medium amount (100k-10M)"),
        (50_000_000, "Large amount (>10M)")
    ]

    for amount, description in test_cases:
        tolerance = get_financial_tolerance(amount)
        relative = (tolerance / amount) * 100
        print(f"\n{description}:")
        print(f"  Amount: {amount:,.0f} SEK")
        print(f"  Tolerance: ¬±{tolerance:,.0f} SEK ({relative:.1f}%)")

    print("\n‚úÖ TEST 1 PASSED: Dynamic tolerance working correctly")
    return True


def test_debt_per_sqm_valid():
    """Test 2: Debt per sqm with VALID status (within tolerance)."""
    print("\n" + "=" * 70)
    print("TEST 2: Debt per sqm - VALID Status (Within Tolerance)")
    print("=" * 70)

    metrics = CalculatedFinancialMetrics(
        # Extracted values
        total_debt_extracted=NumberField(value=99_538_124, confidence=0.98, source='structured_table', evidence_pages=[9]),
        total_area_sqm_extracted=NumberField(value=5_000, confidence=0.95, source='structured_table', evidence_pages=[3]),
        debt_per_sqm_extracted=NumberField(value=19_900, confidence=0.90, source='calculated', evidence_pages=[9])
    )

    # Calculated value should be: 99_538_124 / 5_000 = 19,907.6 ‚âà 19,908 SEK/m¬≤
    # Difference: abs(19_900 - 19_908) = 8 SEK/m¬≤
    # Tolerance: get_financial_tolerance(19_908) = max(5k, 19_908 * 0.15) = 5,000 SEK/m¬≤
    # Status: 8 <= 5,000 ‚Üí VALID ‚úÖ

    print(f"\nExtracted debt: {metrics.total_debt_extracted.value:,.0f} SEK")
    print(f"Extracted area: {metrics.total_area_sqm_extracted.value:,.0f} m¬≤")
    print(f"Extracted debt/m¬≤: {metrics.debt_per_sqm_extracted.value:,.0f} SEK/m¬≤")
    print(f"Calculated debt/m¬≤: {metrics.debt_per_sqm_calculated:,.0f} SEK/m¬≤")
    print(f"\nValidation Status: {metrics.debt_per_sqm_status}")
    print(f"Overall Status: {metrics.validation_status}")
    print(f"Overall Confidence: {metrics.overall_confidence:.2f}")

    assert metrics.debt_per_sqm_status == "valid", f"Expected 'valid', got '{metrics.debt_per_sqm_status}'"
    assert metrics.validation_status == "valid", f"Expected 'valid', got '{metrics.validation_status}'"
    assert metrics.overall_confidence >= 0.90, f"Expected confidence >= 0.90, got {metrics.overall_confidence}"
    assert len(metrics.validation_warnings) == 0, "Should have no warnings"
    assert len(metrics.validation_errors) == 0, "Should have no errors"

    print("\n‚úÖ TEST 2 PASSED: VALID status working correctly")
    return True


def test_solidarity_percent_warning():
    """Test 3: Solidarity percentage with WARNING status (within 2x tolerance)."""
    print("\n" + "=" * 70)
    print("TEST 3: Solidarity Percent - WARNING Status (Within 2x Tolerance)")
    print("=" * 70)

    metrics = CalculatedFinancialMetrics(
        # Extracted values
        equity_extracted=NumberField(value=201_801_694, confidence=0.98, source='structured_table', evidence_pages=[9]),
        assets_extracted=NumberField(value=301_339_818, confidence=0.98, source='structured_table', evidence_pages=[9]),
        solidarity_percent_extracted=NumberField(value=70.0, confidence=0.90, source='calculated', evidence_pages=[9])
    )

    # Calculated value: (201_801_694 / 301_339_818) * 100 = 66.97%
    # Difference: abs(70.0 - 66.97) = 3.03 pp
    # Tolerance: ¬±2 pp
    # Status: 3.03 > 2.0 but <= 4.0 (2x tolerance) ‚Üí WARNING ‚ö†Ô∏è

    print(f"\nExtracted equity: {metrics.equity_extracted.value:,.0f} SEK")
    print(f"Extracted assets: {metrics.assets_extracted.value:,.0f} SEK")
    print(f"Extracted solidarity: {metrics.solidarity_percent_extracted.value:.1f}%")
    print(f"Calculated solidarity: {metrics.solidarity_percent_calculated:.1f}%")
    print(f"\nValidation Status: {metrics.solidarity_percent_status}")
    print(f"Overall Status: {metrics.validation_status}")
    print(f"Overall Confidence: {metrics.overall_confidence:.2f}")
    print(f"Warnings: {metrics.validation_warnings}")

    assert metrics.solidarity_percent_status == "warning", f"Expected 'warning', got '{metrics.solidarity_percent_status}'"
    assert metrics.validation_status == "warning", f"Expected 'warning', got '{metrics.validation_status}'"
    assert 0.65 <= metrics.overall_confidence <= 0.75, f"Expected confidence 0.65-0.75, got {metrics.overall_confidence}"
    assert len(metrics.validation_warnings) == 1, "Should have 1 warning"
    assert len(metrics.validation_errors) == 0, "Should have no errors"

    # CRITICAL: Verify extracted data is preserved (not nulled)
    assert metrics.solidarity_percent_extracted.value == 70.0, "Extracted value should be preserved"
    assert metrics.solidarity_percent_calculated == 67.0, "Calculated value should be present"

    print("\n‚úÖ TEST 3 PASSED: WARNING status working correctly (data preserved)")
    return True


def test_fee_per_sqm_error():
    """Test 4: Fee per sqm with ERROR status (beyond 2x tolerance)."""
    print("\n" + "=" * 70)
    print("TEST 4: Fee per sqm - ERROR Status (Beyond 2x Tolerance)")
    print("=" * 70)

    metrics = CalculatedFinancialMetrics(
        # Extracted values
        monthly_fee_extracted=NumberField(value=5_000, confidence=0.90, source='structured_table', evidence_pages=[5]),
        apartment_area_extracted=NumberField(value=75, confidence=0.95, source='structured_table', evidence_pages=[3]),
        fee_per_sqm_annual_extracted=NumberField(value=1_200, confidence=0.85, source='calculated', evidence_pages=[5])
    )

    # Calculated value: (5_000 * 12) / 75 = 800 SEK/m¬≤/√•r
    # Difference: abs(1_200 - 800) = 400 SEK/m¬≤/√•r
    # Tolerance: get_financial_tolerance(800) = max(5k, 800 * 0.15) = 5,000 SEK/m¬≤/√•r
    # BUT: 400 is small, so let's use a larger extracted value to trigger error

    # Let me recalculate with values that will trigger error:
    # monthly_fee=8000, area=75 ‚Üí calc = 1,280 SEK/m¬≤/√•r
    # extracted=3000, diff=1720
    # tolerance=max(5k, 1280*0.15)=5000, so this is still valid

    # Let's use: monthly=5000, area=50 ‚Üí calc=1200
    # extracted=600, diff=600
    # tolerance=max(5k, 1200*0.15)=5000, still valid

    # Actually, let me create a scenario with LARGER amounts:
    # monthly=10000, area=100 ‚Üí calc=1200
    # extracted=15000, diff=13800
    # tolerance=max(5k, 1200*0.15)=5000
    # 2x tolerance=10000
    # diff=13800 > 10000 ‚Üí ERROR

    metrics2 = CalculatedFinancialMetrics(
        monthly_fee_extracted=NumberField(value=10_000, confidence=0.90, source='structured_table', evidence_pages=[5]),
        apartment_area_extracted=NumberField(value=100, confidence=0.95, source='structured_table', evidence_pages=[3]),
        fee_per_sqm_annual_extracted=NumberField(value=15_000, confidence=0.85, source='calculated', evidence_pages=[5])
    )

    # Calculated: (10_000 * 12) / 100 = 1,200 SEK/m¬≤/√•r
    # Extracted: 15,000 SEK/m¬≤/√•r
    # Diff: 13,800
    # Tolerance: 5,000
    # 2x Tolerance: 10,000
    # Status: 13,800 > 10,000 ‚Üí ERROR ‚ùå

    print(f"\nExtracted monthly fee: {metrics2.monthly_fee_extracted.value:,.0f} SEK")
    print(f"Extracted area: {metrics2.apartment_area_extracted.value:,.0f} m¬≤")
    print(f"Extracted fee/m¬≤/√•r: {metrics2.fee_per_sqm_annual_extracted.value:,.0f} SEK/m¬≤/√•r")
    print(f"Calculated fee/m¬≤/√•r: {metrics2.fee_per_sqm_annual_calculated:,.0f} SEK/m¬≤/√•r")
    print(f"\nValidation Status: {metrics2.fee_per_sqm_status}")
    print(f"Overall Status: {metrics2.validation_status}")
    print(f"Overall Confidence: {metrics2.overall_confidence:.2f}")
    print(f"Errors: {metrics2.validation_errors}")

    assert metrics2.fee_per_sqm_status == "error", f"Expected 'error', got '{metrics2.fee_per_sqm_status}'"
    assert metrics2.validation_status == "error", f"Expected 'error', got '{metrics2.validation_status}'"
    assert 0.35 <= metrics2.overall_confidence <= 0.45, f"Expected confidence 0.35-0.45, got {metrics2.overall_confidence}"
    assert len(metrics2.validation_warnings) == 0, "Should have no warnings"
    assert len(metrics2.validation_errors) == 1, "Should have 1 error"

    # CRITICAL: Verify extracted data is preserved (not nulled)
    assert metrics2.fee_per_sqm_annual_extracted.value == 15_000, "Extracted value should be preserved"
    assert metrics2.fee_per_sqm_annual_calculated == 1_200, "Calculated value should be present"

    print("\n‚úÖ TEST 4 PASSED: ERROR status working correctly (data preserved)")
    return True


def test_calculated_only():
    """Test 5: Calculated-only metrics (no extracted value to compare)."""
    print("\n" + "=" * 70)
    print("TEST 5: Calculated-Only Metrics (No Extracted Value)")
    print("=" * 70)

    metrics = CalculatedFinancialMetrics(
        # Only provide inputs, no extracted metric value
        total_debt_extracted=NumberField(value=100_000_000, confidence=0.98, source='structured_table', evidence_pages=[9]),
        total_area_sqm_extracted=NumberField(value=5_000, confidence=0.95, source='structured_table', evidence_pages=[3])
        # No debt_per_sqm_extracted
    )

    # Should calculate: 100_000_000 / 5_000 = 20,000 SEK/m¬≤
    # Status: calculated_only (confidence 0.85)

    print(f"\nExtracted debt: {metrics.total_debt_extracted.value:,.0f} SEK")
    print(f"Extracted area: {metrics.total_area_sqm_extracted.value:,.0f} m¬≤")
    print(f"Calculated debt/m¬≤: {metrics.debt_per_sqm_calculated:,.0f} SEK/m¬≤")
    print(f"\nValidation Status: {metrics.debt_per_sqm_status}")
    print(f"Overall Status: {metrics.validation_status}")
    print(f"Overall Confidence: {metrics.overall_confidence:.2f}")

    assert metrics.debt_per_sqm_status == "calculated_only", f"Expected 'calculated_only', got '{metrics.debt_per_sqm_status}'"
    assert metrics.validation_status == "calculated_only", f"Expected 'calculated_only', got '{metrics.validation_status}'"
    assert 0.80 <= metrics.overall_confidence <= 0.90, f"Expected confidence 0.80-0.90, got {metrics.overall_confidence}"
    assert metrics.debt_per_sqm_calculated == 20_000, "Calculated value should be 20,000"
    assert len(metrics.validation_warnings) == 0, "Should have no warnings"
    assert len(metrics.validation_errors) == 0, "Should have no errors"

    print("\n‚úÖ TEST 5 PASSED: Calculated-only metrics working correctly")
    return True


def test_no_data():
    """Test 6: No data scenario."""
    print("\n" + "=" * 70)
    print("TEST 6: No Data Scenario")
    print("=" * 70)

    metrics = CalculatedFinancialMetrics()

    print(f"\nValidation Status: {metrics.validation_status}")
    print(f"Overall Confidence: {metrics.overall_confidence:.2f}")

    assert metrics.validation_status == "no_data", f"Expected 'no_data', got '{metrics.validation_status}'"
    assert metrics.overall_confidence == 0.0, "Expected confidence 0.0"
    assert len(metrics.validation_warnings) == 0, "Should have no warnings"
    assert len(metrics.validation_errors) == 0, "Should have no errors"

    print("\n‚úÖ TEST 6 PASSED: No data scenario handled correctly")
    return True


def test_integration_with_financial_data():
    """Test 7: Integration with FinancialData model."""
    print("\n" + "=" * 70)
    print("TEST 7: Integration with FinancialData Model")
    print("=" * 70)

    # Create FinancialData with calculated metrics
    financial_data = FinancialData(
        calculated_metrics=CalculatedFinancialMetrics(
            total_debt_extracted=NumberField(value=99_538_124, confidence=0.98, source='structured_table', evidence_pages=[9]),
            total_area_sqm_extracted=NumberField(value=5_000, confidence=0.95, source='structured_table', evidence_pages=[3]),
            debt_per_sqm_extracted=NumberField(value=19_900, confidence=0.90, source='calculated', evidence_pages=[9])
        )
    )

    print(f"\nFinancialData created successfully")
    print(f"Calculated metrics status: {financial_data.calculated_metrics.validation_status}")
    print(f"Calculated metrics confidence: {financial_data.calculated_metrics.overall_confidence:.2f}")

    assert financial_data.calculated_metrics is not None, "Calculated metrics should be present"
    assert financial_data.calculated_metrics.validation_status == "valid", "Should be valid"

    print("\n‚úÖ TEST 7 PASSED: Integration with FinancialData working correctly")
    return True


def run_all_tests():
    """Run all tests."""
    print("\n" + "=" * 70)
    print("WEEK 2 DAY 1-2: CALCULATED FINANCIAL METRICS TEST SUITE")
    print("=" * 70)

    tests = [
        test_dynamic_tolerance,
        test_debt_per_sqm_valid,
        test_solidarity_percent_warning,
        test_fee_per_sqm_error,
        test_calculated_only,
        test_no_data,
        test_integration_with_financial_data
    ]

    results = []
    for test_func in tests:
        try:
            result = test_func()
            results.append((test_func.__name__, "PASSED" if result else "FAILED", None))
        except Exception as e:
            print(f"\n‚ùå TEST FAILED: {test_func.__name__}")
            print(f"Error: {e}")
            traceback.print_exc()
            results.append((test_func.__name__, "FAILED", str(e)))

    # Summary
    print("\n" + "=" * 70)
    print("TEST SUMMARY")
    print("=" * 70)

    passed = sum(1 for _, status, _ in results if status == "PASSED")
    failed = sum(1 for _, status, _ in results if status == "FAILED")

    for test_name, status, error in results:
        status_icon = "‚úÖ" if status == "PASSED" else "‚ùå"
        print(f"{status_icon} {test_name}: {status}")
        if error:
            print(f"   Error: {error}")

    print("\n" + "=" * 70)
    print(f"TOTAL: {passed}/{len(tests)} tests passed ({passed/len(tests)*100:.1f}%)")
    print("=" * 70)

    if failed == 0:
        print("\nüéâ ALL TESTS PASSED! Week 2 Day 1-2 COMPLETE!")
        return True
    else:
        print(f"\n‚ö†Ô∏è  {failed} tests failed. Please review.")
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
